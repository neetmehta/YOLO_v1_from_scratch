{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import os\n",
    "from os.path import join as osp\n",
    "from PIL import Image\n",
    "from torchvision.transforms import transforms\n",
    "\n",
    "img_transforms = transforms.Compose([transforms.Resize((384,1248)), transforms.ToTensor()])\n",
    "\n",
    "label_map = {\n",
    "                'Car':                 0,\n",
    "                'Van':                 1,\n",
    "                'Truck':               2,\n",
    "                'Pedestrian':          3,\n",
    "                'Person_sitting':      4,\n",
    "                'Cyclist':             5,\n",
    "                'Tram':                6,\n",
    "                'Misc':                7,\n",
    "                'DontCare':            8\n",
    "            }\n",
    "\n",
    "class KittiDetection2D(Dataset):\n",
    "\n",
    "    def __init__(self, root, transforms=None):\n",
    "        super(KittiDetection2D, self).__init__()\n",
    "        self.image_dir = osp(root, \"image_2\")\n",
    "        self.label_dir = osp(root, \"label_2\")\n",
    "        self.image_list = os.listdir(osp(root, \"image_2\"))\n",
    "        self.label_list = os.listdir(osp(root, \"label_2\"))\n",
    "        self.transforms = transforms\n",
    "        self.h = 384\n",
    "        self.w = 1248\n",
    "        self.S = (11,24)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_list)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image = Image.open(osp(self.image_dir, self.image_list[index]))\n",
    "        label_pth = osp(self.label_dir, self.label_list[index])\n",
    "        target = torch.zeros(11, 24, 14)\n",
    "        with open(label_pth, 'r') as f:\n",
    "            for i in f.readlines():\n",
    "                obj_class, x1, y1, x2, y2 = self._parse_label(i)\n",
    "                cell, x, y, w, h = self._convert_label(x1, y1, x2, y2)\n",
    "                target[cell[0], cell[1]] = self._create_vector(obj_class, x, y, w, h)\n",
    "            \n",
    "        if self.transforms:\n",
    "            image = self.transforms(image)\n",
    "\n",
    "        return image, target\n",
    "\n",
    "    def _create_vector(self, obj, x, y, h, w):\n",
    "        obj_vector = torch.zeros(9)\n",
    "        obj_vector[obj] = 1\n",
    "        return torch.cat((obj_vector, torch.tensor([1,x,y,h,w])))\n",
    "\n",
    "    def _parse_label(self, label):\n",
    "        label = label.split()\n",
    "        obj_class = label_map[label[0]]\n",
    "        x1, y1, x2, y2 = int(float(label[4])), int(float(label[5])), int(float(label[6])), int(float(label[7]))\n",
    "        return obj_class, x1, y1, x2, y2\n",
    "\n",
    "    def _convert_label(self, x1, y1, x2, y2):\n",
    "        x = int((x1+x2)/2)/self.w\n",
    "        y = int((y1+y2)/2)/self.h\n",
    "        h = int((y2-y1))/self.h\n",
    "        w = int((x2-x1))/self.w\n",
    "        cell = int(y*self.S[0]), int(x*self.S[1])\n",
    "        x = x*self.S[1]-cell[1]\n",
    "        y = y*self.S[0]-cell[0]\n",
    "        h = self.S[0]*h\n",
    "        w = self.S[1]*w\n",
    "        return cell,x,y,w,h\n",
    "\n",
    "ds = KittiDetection2D(r\"E:\\Deep Learning Projects\\datasets\\kitti_object_detection\\Kitti\\raw\\training\", img_transforms)\n",
    "x, target = ds[2]\n",
    "x.unsqueeze_(0)\n",
    "target.unsqueeze_(0)\n",
    "from model import YOLOv1\n",
    "from utils import read_yaml, iou\n",
    "\n",
    "model_cfg = read_yaml('model.yaml')\n",
    "model = YOLOv1(model_cfg)\n",
    "pred = model(x)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.where(target[0,..., 9]==1)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import MSELoss\n",
    "import torch.nn as nn\n",
    "loss = MSELoss()\n",
    "tar_b = target[..., 10:14]\n",
    "exists_box = target[...,9:10]\n",
    "\n",
    "pred_b1 = pred[...,10:14]\n",
    "pred_b2 = pred[..., 15:19]\n",
    "iou_b1 = iou(pred_b1, tar_b).unsqueeze(-1)\n",
    "iou_b2 = iou(pred_b2, tar_b).unsqueeze(-1)\n",
    "_, best_box = torch.max(torch.cat((iou_b1,iou_b2), dim=-1), dim=-1)\n",
    "best_box.unsqueeze_(-1)\n",
    "pred_b = exists_box*(best_box*pred[..., 15:19] + (1-best_box)*pred[..., 10:14])\n",
    "pred_coord = pred_b[...,0:2]\n",
    "target_coord = tar_b[...,0:2]\n",
    "coord_loss = 5*loss(torch.flatten(pred_coord,0,-2), torch.flatten(target_coord,0,-2))\n",
    "print(coord_loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yololoss = YoloLoss()\n",
    "yololoss(pred, target)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from utils import iou\n",
    "\n",
    "class YoloLoss(nn.Module):\n",
    "    def __init__(self, S=(11,24), B=2, C=9, coord=5, noobj=0.5) -> None:\n",
    "        super(YoloLoss, self).__init__()\n",
    "        self.mse_loss = nn.MSELoss()\n",
    "        self.S = S\n",
    "        self.B = B\n",
    "        self.C = C\n",
    "        self.coord = coord\n",
    "        self.noobj = noobj\n",
    "\n",
    "    def forward(self, pred, target):\n",
    "\n",
    "        class_probs = target[..., :self.C]                              # [N, S[0], s[1], C]\n",
    "        exist_box_identity = target[..., self.C:self.C+1]\n",
    "        target_box = exist_box_identity * target[..., self.C+1:]                       # [N, S[0], s[1], 4]\n",
    "\n",
    "        iou_b1 = iou(pred[..., 10:14], target[...,10:14]).unsqueeze(-1) # [N, S[0], S[1], 1]\n",
    "        iou_b2 = iou(pred[...,15:19], target[..., 10:14]).unsqueeze(-1) # [N, S[0], S[1], 1]\n",
    "        max_iou, best_box = torch.max(torch.cat((iou_b1,iou_b2), dim=-1), dim=-1)            # best_box [N, S[0], S[1]]\n",
    "        best_box = best_box.unsqueeze(-1)\n",
    "        pred_best_box = exist_box_identity*(best_box*pred[...,15:19] + (1-best_box)*pred[..., 10:14]) # [N, S[0], s[1], 4]\n",
    "        \n",
    "        ## coord loss\n",
    "        pred_coord = pred_best_box[..., 0:2]\n",
    "        target_coord = target_box[..., 0:2]\n",
    "        coord_loss = self.coord*self.mse_loss(torch.flatten(pred_coord, 0, -2), torch.flatten(target_coord, 0, -2))\n",
    "\n",
    "        ## box loss\n",
    "        \n",
    "        pred_h_w = torch.sign(pred_best_box[...,2:4])*torch.sqrt(torch.abs(pred_best_box[..., 2:4])) # [N, S[0], S[1], 2]\n",
    "        target_h_w = torch.sqrt(target_box[..., 2:4]) #[N, S[0], S[1], 2]\n",
    "        box_loss = self.coord*self.mse_loss(torch.flatten(pred_h_w, 0, -2), torch.flatten(target_h_w, 0, -2))\n",
    "\n",
    "        ## object loss\n",
    "        pred_obj = exist_box_identity*(best_box*pred[...,14:15] + (1-best_box)*pred[..., 9:10])\n",
    "\n",
    "        object_loss = self.mse_loss(torch.flatten(pred_obj, 0, -2), torch.flatten(exist_box_identity, 0, -2))\n",
    "\n",
    "        ## no object loss\n",
    "\n",
    "        noobject_loss = self.mse_loss(torch.flatten((1-exist_box_identity)*pred[...,9:10], 0, -2), torch.flatten((1-exist_box_identity)*target[...,9:10], 0, -2)) + self.mse_loss(torch.flatten((1-exist_box_identity)*pred[...,9:10], 0, -2), torch.flatten((1-exist_box_identity)*target[...,9:10], 0, -2))      ###### CHECK\n",
    "        noobject_loss = self.noobj*object_loss\n",
    "\n",
    "        ## class loss\n",
    "        pred_class = exist_box_identity*pred[..., :9]\n",
    "        target_class = exist_box_identity*target[..., :9]\n",
    "\n",
    "        class_loss = self.mse_loss(torch.flatten(pred_class, 0, -2), torch.flatten(target_class, 0, -2))\n",
    "        print('cord loss', coord_loss)\n",
    "        # print('box loss', box_loss)\n",
    "        # print('obj loss', object_loss)\n",
    "        # print('noobj loss', noobject_loss)\n",
    "        # print('class loss', class_loss)\n",
    "\n",
    "        return box_loss + coord_loss + object_loss + noobject_loss + class_loss\n",
    "        \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = YoloLoss()\n",
    "loss(torch.rand(1,11,24,19), torch.rand(1,11,24,14))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iou_b1 = iou(torch.rand(1,11,24,4), torch.rand(1,11,24,4)).unsqueeze(-1)\n",
    "iou_b2 = iou(torch.rand(1,11,24,4), torch.rand(1,11,24,4)).unsqueeze(-1)\n",
    "max_iou, best_box = torch.max(torch.cat((iou_b1,iou_b2), dim=-1), dim=-1)\n",
    "best_box.unsqueeze_(-1)\n",
    "pred_box = best_box * torch.rand(1,11,24,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.rand(1,11,24,4)[..., :5].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_box.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.flatten(torch.rand(1,11,24,4), 0,-2).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data import VOCDataset\n",
    "from torchvision.transforms import transforms\n",
    "from model import YOLOv1\n",
    "from model2 import Yolov1\n",
    "from utils import read_yaml, iou\n",
    "\n",
    "model_cfg = read_yaml('model.yaml')\n",
    "model = YOLOv1(model_cfg)\n",
    "model2 = Yolov1(split_size=7, num_boxes=2, num_classes=20)\n",
    "img_transforms = transforms.Compose([transforms.Resize((448,448)), transforms.ToTensor()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = VOCDataset(r\"E:\\Deep Learning Projects\\datasets\\voc\\train.csv\", r\"E:\\Deep Learning Projects\\datasets\\voc\\images\" ,r\"E:\\Deep Learning Projects\\datasets\\voc\\labels\", transform=img_transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(i.numel() for i in model2.parameters()) - sum(i.numel() for i in model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "YOLOv1(\n",
       "  (backbone): Sequential(\n",
       "    (0): Sequential(\n",
       "      (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3))\n",
       "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.1)\n",
       "    )\n",
       "    (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (2): Sequential(\n",
       "      (0): Conv2d(64, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.1)\n",
       "    )\n",
       "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (4): Sequential(\n",
       "      (0): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.1)\n",
       "    )\n",
       "    (5): Sequential(\n",
       "      (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.1)\n",
       "    )\n",
       "    (6): Sequential(\n",
       "      (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.1)\n",
       "    )\n",
       "    (7): Sequential(\n",
       "      (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.1)\n",
       "    )\n",
       "    (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (9): Sequential(\n",
       "      (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.1)\n",
       "    )\n",
       "    (10): Sequential(\n",
       "      (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.1)\n",
       "    )\n",
       "    (11): Sequential(\n",
       "      (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.1)\n",
       "    )\n",
       "    (12): Sequential(\n",
       "      (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.1)\n",
       "    )\n",
       "    (13): Sequential(\n",
       "      (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.1)\n",
       "    )\n",
       "    (14): Sequential(\n",
       "      (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.1)\n",
       "    )\n",
       "    (15): Sequential(\n",
       "      (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.1)\n",
       "    )\n",
       "    (16): Sequential(\n",
       "      (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.1)\n",
       "    )\n",
       "    (17): Sequential(\n",
       "      (0): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.1)\n",
       "    )\n",
       "    (18): Sequential(\n",
       "      (0): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.1)\n",
       "    )\n",
       "    (19): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (20): Sequential(\n",
       "      (0): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.1)\n",
       "    )\n",
       "    (21): Sequential(\n",
       "      (0): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.1)\n",
       "    )\n",
       "    (22): Sequential(\n",
       "      (0): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.1)\n",
       "    )\n",
       "    (23): Sequential(\n",
       "      (0): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.1)\n",
       "    )\n",
       "    (24): Sequential(\n",
       "      (0): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.1)\n",
       "    )\n",
       "    (25): Sequential(\n",
       "      (0): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.1)\n",
       "    )\n",
       "    (26): Sequential(\n",
       "      (0): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.1)\n",
       "    )\n",
       "    (27): Sequential(\n",
       "      (0): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.1)\n",
       "    )\n",
       "  )\n",
       "  (fcl): Sequential(\n",
       "    (0): Flatten(start_dim=1, end_dim=-1)\n",
       "    (1): Linear(in_features=50176, out_features=496, bias=True)\n",
       "    (2): Dropout(p=0.0, inplace=False)\n",
       "    (3): LeakyReLU(negative_slope=0.1)\n",
       "    (4): Linear(in_features=496, out_features=1470, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1575035622ce78d0fdd034cce6fb6336dc5a68a5b98817405196dd053fee3f88"
  },
  "kernelspec": {
   "display_name": "Python 3.7.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
